{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcf6da57",
   "metadata": {},
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d3dbb08b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "from tensorflow.keras.models import load_model\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import cv2\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#################### Importing wheigts #####################################\n",
    "from tensorflow.keras.applications import EfficientNetB0\n",
    "from tensorflow.keras.applications import EfficientNetB4\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.applications import VGG19\n",
    "from tensorflow.keras.applications import mobilenet_v2\n",
    "from tensorflow.keras.applications import mobilenet_v3\n",
    "from tensorflow.keras.applications import NASNetMobile\n",
    "from tensorflow.keras.applications import NASNetLarge, Xception\n",
    "#########################################################\n",
    "\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint, CSVLogger\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import ipywidgets as widgets\n",
    "import io\n",
    "from PIL import Image\n",
    "from IPython.display import display,clear_output\n",
    "from warnings import filterwarnings\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ae86b72",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c1489f8",
   "metadata": {},
   "source": [
    "First im going to do some image augmentations in order to increase our dataset samples then apply the image_resizer function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "871ec1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966eaf1b",
   "metadata": {},
   "source": [
    "First rename all the files in order to be sure of the results of augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248cd245",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    " \n",
    "# os.chdir('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Testing\\\\no_tumor')\n",
    "# print(os.getcwd())\n",
    " \n",
    "# for count, f in enumerate(os.listdir()):\n",
    "#     f_name, f_ext = os.path.splitext(f)\n",
    "#     f_name = \"NT_\" + str(count)\n",
    " \n",
    "#     new_name = f'{f_name}{f_ext}'\n",
    "#     os.rename(f, new_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "477bfc1f",
   "metadata": {},
   "source": [
    "# In progress .........................................."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87363ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining Global Variables\n",
    "image_size = 224\n",
    "def_labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']\n",
    "# root = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data'\n",
    "# destination = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Augmented'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "69a07422",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_data_augmentation(idx):\n",
    "    \n",
    "#     \"\"\"Defining Image augmenter\"\"\"\n",
    "#     train_datagen = ImageDataGenerator(\n",
    "# #         rotation_range=75,\n",
    "#         brightness_range=[1.0,2.25],\n",
    "#         channel_shift_range=-5.0,\n",
    "#         fill_mode='nearest',\n",
    "#         horizontal_flip=True,\n",
    "#         vertical_flip=True\n",
    "#         )\n",
    "    \n",
    "    \n",
    "#     \"\"\"Now we are going to iterate over each label and augment the corresponding images and save them in the different dir\"\"\"\n",
    "    \n",
    "# #     folderPath = os.path.join(root,'Training',idx) \n",
    "# #     for j in tqdm(os.listdir(folderPath)):\n",
    "#     i = 0\n",
    "#     for batch in train_datagen.flow_from_directory(\n",
    "# #         \"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training\",\n",
    "#         \"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training\",\n",
    "#         target_size=(224,224),\n",
    "# #         batch_size=len(os.listdir(os.path.join(root,'Training',idx))),\n",
    "#         batch_size=len(os.listdir(os.path.join(root,'Training',idx))),\n",
    "#         class_mode='categorical',\n",
    "#         save_to_dir= f\"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Augmented\\\\{idx}\",\n",
    "#         save_format=\"jpg\",\n",
    "#         save_prefix=f'{idx.upper()}_TR_AUG_',\n",
    "#         seed=123):\n",
    "\n",
    "#         print(i)\n",
    "#         i += 1\n",
    "#         if i > 2:\n",
    "#             break\n",
    "            \n",
    "# #     return train_generator\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93d42ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_data_augmentation(idx):        \n",
    "#     \"\"\"Defining Image augmenter\"\"\"\n",
    "#     # We dont need to Augment the Test Data, atleast not yet! Just resize and shuffle them inside their directory\n",
    "#     validation_datagen = ImageDataGenerator(\n",
    "#     zca_whitening=True,\n",
    "#     zca_epsilon=0.00001,\n",
    "#     rotation_range=30,\n",
    "#     width_shift_range=0.17,\n",
    "#     height_shift_range=0.17,\n",
    "#     brightness_range=[1.0,2.25],\n",
    "#     shear_range=10.0,\n",
    "#     channel_shift_range=-5.0,\n",
    "#     fill_mode='nearest',\n",
    "#     horizontal_flip=True,\n",
    "#     vertical_flip=True\n",
    "#     )\n",
    "    \n",
    "    \n",
    "#     \"\"\"Now we are going to iterate over each label and augment the corresponding images and save them in the different dir\"\"\"    \n",
    "#     k = 0\n",
    "#     folderPath = os.path.join(root,'Testing',idx)    \n",
    "#     for j in tqdm(os.listdir(folderPath)):   \n",
    "#         for batch in validation_datagen.flow_from_directory(\n",
    "#                         \"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Testing\",\n",
    "#                         target_size=(150,150),\n",
    "#                         batch_size=32,\n",
    "#                         save_to_dir=f\"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Augmented\\\\TestData_Augmented\\\\{idx}\",\n",
    "#                         save_format=\"jpg\",\n",
    "#                         save_prefix=f'{idx.upper()}_TS_AUG_',\n",
    "#                         class_mode='categorical',\n",
    "#                         shuffle=True):\n",
    "#                         k += 1\n",
    "#                         if k>= 10: \n",
    "#                             break  \n",
    "    \n",
    "#     return validation_generator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ddf15f",
   "metadata": {},
   "source": [
    "# ..............................................................."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b59e4eba",
   "metadata": {},
   "source": [
    "# Defining a function to create CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96b1976",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"EfficientNetB0 Implementation\"\n",
    "EfficientNetB0 = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "# model = EfficientNetB0.output\n",
    "# model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "# model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "# model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "# model = tf.keras.models.Model(inputs=EfficientNetB0.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bead47",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"VGG16 Implementation\"\n",
    "# VGG16 = VGG16(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "# model = VGG16.output\n",
    "# model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "# model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "# model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "# model = tf.keras.models.Model(inputs=VGG16.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a26af58",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"VGG19 Implementation\"\n",
    "# VGG19 = VGG19(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "# model = VGG19.output\n",
    "# model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "# model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "# model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "# model = tf.keras.models.Model(inputs=VGG19.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c091529",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"mobilenet_v2 Implementation\"\n",
    "# mobilenet_v2 = mobilenet_v2(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "# model = mobilenet_v2.output\n",
    "# model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "# model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "# model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "# model = tf.keras.models.Model(inputs=mobilenet_v2.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd5cee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"mobilenet_v3 Implementation\"\n",
    "# mobilenet_v3 = mobilenet_v3(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))\n",
    "# model = mobilenet_v3.output\n",
    "# model = tf.keras.layers.GlobalAveragePooling2D()(model)\n",
    "# model = tf.keras.layers.Dropout(rate=0.5)(model)\n",
    "# model = tf.keras.layers.Dense(4,activation='softmax')(model)\n",
    "# model = tf.keras.models.Model(inputs=mobilenet_v3.input, outputs = model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e45731",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In case http Error\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86359f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cddd8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # tensorboard = TensorBoard(log_dir = 'logs')\n",
    "# csv_logger = CSVLogger('C:\\\\Users\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\Logs_v1.csv',separator=\",\")\n",
    "# checkpoint = ModelCheckpoint(\"Just_a_model.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\n",
    "# reduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n",
    "#                               mode='auto',verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419d3409",
   "metadata": {},
   "source": [
    "\"\"\"Augment the each tumor Data separately\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "44953b5a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 106 images belonging to 3 classes.\n",
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# train_data_augmentation(idx = 'meningioma_tumor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e969e222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator = test_data_augmentation(idx = 'no_tumor')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191c9567",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train_generator(TRAINING_DIR):\n",
    "    \n",
    "#     train_datagen = ImageDataGenerator(rescale=1/255)\n",
    "#     train_generator = train_datagen.flow_from_directory(directory=TRAINING_DIR, \n",
    "#                                                         batch_size=30,\n",
    "#                                                         class_mode='categorical',\n",
    "#                                                         target_size=(150, 150))\n",
    "    \n",
    "#     return train_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ee0386a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def test_generator(TEST_DIR):    \n",
    "    \n",
    "#     test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "#     test_generator = test_datagen.flow_from_directory(directory=TEST_DIR,\n",
    "#                                                       batch_size=30,\n",
    "#                                                       class_mode='categorical',\n",
    "#                                                       target_size=(150,150))\n",
    "    \n",
    "#     return test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7200aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dir = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training'\n",
    "Test_Dir = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b6136c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_generator' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_generator\u001b[49m(TRAINING_DIR\u001b[38;5;241m=\u001b[39mTrain_Dir)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'train_generator' is not defined"
     ]
    }
   ],
   "source": [
    "training_generator = train_generator(TRAINING_DIR=Train_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d4bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validation_generator = test_generator(TEST_DIR=Test_Dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d588df7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we need to define a function to extract features\n",
    "from keras.preprocessing import image\n",
    "from keras.applications.efficientnet import preprocess_input\n",
    "\n",
    "# def get_features(path):\n",
    "#     img = image.load_img(path, target_size=(150,150))\n",
    "#     img_data = image.img_to_array(img)\n",
    "#     img_data = np.expand_dims(img_data, axis=0)\n",
    "#     img_data = preprocess_input(img_data)\n",
    "#     features = EfficientNetB0.predict(img_data)\n",
    "#     return features\n",
    "\n",
    "# path = \"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training\\\\glioma_tumor\\\\GLIOMA_TUMOR_TR_AUG__2_9770519.jpg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d13b4cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_features = get_features(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ca9715",
   "metadata": {},
   "source": [
    "now the extracted features are stored in the variable. \n",
    "One can flatten them or sequee them in order to use them in ML models. \n",
    "Flatten will produce a long vector of feature elements. \n",
    "Squeeze will produce a 3D matrix of the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "588ac228",
   "metadata": {},
   "outputs": [],
   "source": [
    "# deep_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "792618d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_flatten_repr = deep_features.flatten()\n",
    "# print (\"flatten: \", features_flatten_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d34c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features_squeeze_repr = deep_features.squeeze()\n",
    "# print (\"squeeze: \", features_squeeze_repr.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148bb51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Train_Dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e133e68",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_features = {}\n",
    "root = 'C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training\\\\glioma_tumor'\n",
    "for idx in os.listdir(root):\n",
    "    # Read them from their path\n",
    "    path = os.path.join(root,idx)\n",
    "    # Load each one of them\n",
    "    img = image.load_img(path, target_size=(150, 150))\n",
    "    # Prep them \n",
    "    img_data = image.img_to_array(img)\n",
    "    img_data = np.expand_dims(img_data, axis=0)\n",
    "    img_data = preprocess_input(img_data)\n",
    "    # Extract the features\n",
    "    features = EfficientNetB0.predict(img_data)\n",
    "    \"\"\"Faltten them all and then append them to a dictionary\"\"\"    \n",
    "    features = features.flatten()\n",
    "    GT_features[idx] = features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688d7a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(GT_features['GLIOMA_TUMOR_TR_AUG__0_1334593.jpg'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd701f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GT_features_train = pd.DataFrame()\n",
    "for key, value in GT_features.items():\n",
    "    temp_df = pd.DataFrame(value)\n",
    "    temp_df['key'] = key\n",
    "    GT_features_train = GT_features_train.append(temp_df, ignore_index=True)\n",
    "GT_features_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e37885",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063d2382",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EPOCHS = 100\n",
    "\n",
    "# history_1 = model.fit(\n",
    "#         train_generator,\n",
    "#         steps_per_epoch=10,\n",
    "#         epochs=EPOCHS,\n",
    "#         verbose=1,\n",
    "#         validation_data = validation_generator,\n",
    "#         callbacks=[csv_logger,checkpoint,reduce_lr]\n",
    "#         )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e0a293",
   "metadata": {},
   "source": [
    "# Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2cd8f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(os.listdir('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22df7bac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# EfficientNetB0 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\EfficientNetB0.csv')\n",
    "# EfficientNetB5 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\EfficientNetB5.csv')\n",
    "# MobileNet = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\MobileNet.csv')\n",
    "# MobileNetV3Large = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\MobileNetV3Large.csv')\n",
    "# ResNet101V2 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\ResNet101V2.csv')\n",
    "# ResNet152V2 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\ResNet152V2.csv')\n",
    "# VGG16 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\VGG16.csv')\n",
    "# VGG19 = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\VGG19.csv')\n",
    "# Xception = pd.read_csv('C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Visulizations\\\\TrainingLogs\\\\Xception.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481addff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Create figure with secondary y-axis\n",
    "# fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# # Add traces\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=EfficientNetB0['val_accuracy'], name=\"EfficientNetB0 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=EfficientNetB5['val_accuracy'], name=\"EfficientNetB5 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=MobileNet['val_accuracy'], name=\"MobileNet Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=MobileNetV3Large['val_accuracy'], name=\"MobileNetV3Large Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=ResNet101V2['val_accuracy'], name=\"ResNet101V2 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=ResNet152V2['val_accuracy'], name=\"ResNet152V2 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=VGG16['val_accuracy'], name=\"VGG16 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=VGG19['val_accuracy'], name=\"VGG19 Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=Xception['val_accuracy'], name=\"Xception Model\"),\n",
    "#     secondary_y=True,\n",
    "# )\n",
    "\n",
    "# # Add figure title\n",
    "# fig.update_layout(\n",
    "#     title_text=\"Validation Accuracy of Models\"\n",
    "# )\n",
    "\n",
    "# # Set x-axis title\n",
    "# fig.update_xaxes(title_text=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d4fa1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import plotly.graph_objects as go\n",
    "# from plotly.subplots import make_subplots\n",
    "\n",
    "# # Create figure with secondary y-axis\n",
    "# fig = make_subplots(specs=[[{\"secondary_y\": True}]])\n",
    "\n",
    "# # Add traces\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=EfficientNetB0['val_loss'], name=\"EfficientNetB0 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=EfficientNetB5['val_loss'], name=\"EfficientNetB5 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=MobileNet['val_loss'], name=\"MobileNet Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=MobileNetV3Large['val_loss'], name=\"MobileNetV3Large Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=ResNet101V2['val_loss'], name=\"ResNet101V2 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=ResNet152V2['val_loss'], name=\"ResNet152V2 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=VGG16['val_loss'], name=\"VGG16 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=VGG19['val_loss'], name=\"VGG19 Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "# fig.add_trace(\n",
    "#     go.Scatter( y=Xception['val_loss'], name=\"Xception Model\"),\n",
    "#     secondary_y=False,\n",
    "# )\n",
    "\n",
    "\n",
    "# # Add figure title\n",
    "# fig.update_layout(\n",
    "#     title_text=\"Validation Loss of Models\"\n",
    "# )\n",
    "\n",
    "# # Set x-axis title\n",
    "# fig.update_xaxes(title_text=\"Epoch\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f784215",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ac339fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5522709",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f5de5be7",
   "metadata": {},
   "source": [
    "Load the Tensorboard(In case you wanted more detail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27160852",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f8d5c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tensorboard --logdir logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cfc8d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since there are some duplicates we need to seach and clear them before working on them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc9249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install difPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a866580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Search for duplicates\n",
    "# from difPy import dif\n",
    "# search = dif(\"C:\\\\Users\\\\Eurus\\\\Desktop\\\\B.Sc_Project\\\\Data\\\\Training\\\\pituitary_tumor\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb8a2c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# search.result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cd05ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # A simple function to clean the data\n",
    "# for idx in search.result.values():\n",
    "#     path = idx['location']\n",
    "#     print(path)\n",
    "#     os.remove(path)\n",
    "#     print(f\"{idx['filename']} removed from {path}\")\n",
    "#     print(\"=============================================================\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd681b49",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU-2022",
   "language": "python",
   "name": "gpu-2022"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
